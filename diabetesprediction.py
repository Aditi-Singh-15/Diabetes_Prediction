# -*- coding: utf-8 -*-
"""DiabetesPrediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o3IEOJ0KKQhzJzsTB0VKsdDoMNhtghIM

Importing the dependencies
"""

import numpy as np # create numpy arrays or matrices
import pandas as pd # creating dataframes(tabular format) , data manipulation
from sklearn.preprocessing import StandardScaler # to standardize (to have similar range)
from sklearn.model_selection import train_test_split # for splitting
from sklearn.metrics import accuracy_score
from sklearn import svm

"""Data collection and analysis,
PIMA Diabetes Dataset
"""

#loading the dataset to a pandas DataFrame
df=pd.read_csv('/content/diabetes.csv')

pd.read_csv?

#printing the first 5 rows of the dataset
df.head()

# printing the number of rows and columns
df.shape

# getting the statistical measures of the data
df.describe()

df['Outcome'].value_counts()

"""0 ---> Non Diabetic
1 ---> Diabetic
"""

df.groupby('Outcome').mean()

# separating the data and labels
X=df.drop(columns='Outcome',axis=1) # drop a ROW(axis=0), COLUMN(axis=1)
Y=df['Outcome']

print(X)

print(Y)

"""Data Standardization"""

scaler2=StandardScaler() #creating an instance of the object
#scaler.fit_transform (X)

scaler2.fit(X)

standardized_data=scaler2.transform(X)

print(standardized_data)

X=standardized_data
Y=df['Outcome']

print(X)
print(Y)

"""Train Test Split"""

X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=2)
# stratify use- subsets have same proportions of class labels as the input dataset.
# random_state use- produce the same splitting datasets

print(X.shape, X_train.shape, X_test.shape)

"""Training the model"""

classifier2=svm.SVC(kernel='linear')

#training the svm classifier
classifier2.fit(X_train,Y_train)

"""Model Evaluation

Accuracy Score
"""

#accuracy score on the training data
X_train_prediction= classifier2.predict(X_train)
training_data_accuracy=accuracy_score(X_train_prediction,Y_train)

print('Accuracy score of the training data : ', training_data_accuracy)

#accuracy score on the testing data
X_test_prediction= classifier2.predict(X_test)
testing_data_accuracy=accuracy_score(X_test_prediction,Y_test)

print('Accuracy score of the testing data : ', testing_data_accuracy)

"""Making a predictive system"""

input_data = (1,103,30,38,83,43.3,0.183,33)

# changing the input_data to numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape the array as we are predicting for one instance
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1) # 1- specifies a single row , -1 tells NumPy to automatically calculate the number of columns
                                                               #based on the total number of elements and the specified row count.

# standardize the input data
std_data = scaler2.transform(input_data_reshaped)
print(std_data)

prediction = classifier2.predict(std_data)
print(prediction) # it returns a list

if (prediction[0] == 0):
  print('The person is not diabetic')
else:
  print('The person is diabetic')

"""Saving the trained model"""

import pickle

filename='diabetes_trained_model.sav'
pickle.dump(classifier2,open(filename,'wb')) # opening the filename file and writing the classifier model in binary , dump to save the model

# Load the saved model
loaded_model1 = pickle.load(open('diabetes_trained_model.sav', 'rb')) # rb means reading binary format
with open('scaler2.sav', 'wb') as scaler_file:
    pickle.dump(scaler2, scaler_file)
# Load the scaler if you saved it separately
scaler2 = pickle.load(open('scaler2.sav', 'rb'))  # Adjust path as needed, rb means reading binary format

input_data = (1, 103, 30, 38, 83, 43.3, 0.183, 33)

# Change the input_data to a numpy array
input_data_as_numpy_array = np.asarray(input_data)

# Reshape the array for one instance
input_data_reshaped = input_data_as_numpy_array.reshape(1, -1) # 1- specifies a single row , -1 tells NumPy to automatically calculate the number of columns
                                                              # based on the total number of elements and the specified row count.

# Standardize the input data
std_data = scaler2.transform(input_data_reshaped)
print(std_data)

# Make prediction
prediction = loaded_model1.predict(std_data)
print(prediction)  # This should now return consistent results

if prediction[0] == 0:
    print('The person is not diabetic')
else:
    print('The person is diabetic')